{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM STATEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New York City is a thriving metropolis. Just like most other metros its size, one of the biggest problems its citizens face is parking. The classic combination of a huge number of cars and cramped geography leads to a huge number of parking tickets.\n",
    "#### In an attempt to scientifically analyse this phenomenon, the NYC Police Department has collected data for parking tickets. Of these, the data files for multiple years are publicly available on Kaggle. We will try and perform some exploratory analysis on #a part of this data. Spark will allow us to analyse the full files at high speeds as opposed to taking a series of random #samples that will approximate the population. For the scope of this analysis, we will analyse the parking tickets over the year 2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class pyspark.sql.SparkSession, The entry point to programming Spark with the Dataset and DataFrame API.\n",
    "#A SparkSession can be used create DataFrame, register DataFrame as tables, execute SQL over tables, cache tables, and \n",
    "# read parquet files.To create a SparkSession, use the following builder pattern:\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"NYC Parking Ticket Assignment\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|    5092469481| GZH7067|                NY|2016-07-10 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|         0143A|\n",
      "|    5092451658| GZH7067|                NY|2016-07-08 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|         0400P|\n",
      "|    4006265037| FZX9232|                NY|2016-08-23 00:00:00|             5|             SUBN|        FORD|                 0|              0|         0233P|\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|         1120A|\n",
      "|    7868300310| 37033JV|                NY|2016-11-21 00:00:00|            69|             DELV|       INTER|                13|             13|         0555P|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Datafram can be created by by calling read method on spark object\n",
    "\n",
    "tickets = spark.read.csv(\"/common_folder/nyc_parking/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\", inferSchema=True,header=True)\n",
    "tickets.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Summons Number: long (nullable = true)\n",
      " |-- Plate ID: string (nullable = true)\n",
      " |-- Registration State: string (nullable = true)\n",
      " |-- Issue Date: timestamp (nullable = true)\n",
      " |-- Violation Code: integer (nullable = true)\n",
      " |-- Vehicle Body Type: string (nullable = true)\n",
      " |-- Vehicle Make: string (nullable = true)\n",
      " |-- Violation Precinct: integer (nullable = true)\n",
      " |-- Issuer Precinct: integer (nullable = true)\n",
      " |-- Violation Time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tickets.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1: Examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|Total Count Of Tickets(2017)|\n",
      "+----------------------------+\n",
      "|                     5431918|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.the total number of tickets for the year 2017\n",
    "from pyspark.sql.functions import count, year\n",
    "\n",
    "total_ticket_count_2017 = tickets.filter(year(\"Issue Date\")==2017).agg(count(\"Summons Number\"))\n",
    "total_ticket_count_2017 = total_ticket_count_2017.withColumnRenamed(\"count(Summons Number)\", \"Total Count Of Tickets(2017)\")\n",
    "total_ticket_count_2017.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|Registration State|  count|\n",
      "+------------------+-------+\n",
      "|                NY|4273951|\n",
      "|                NJ| 475825|\n",
      "|                PA| 140286|\n",
      "|                CT|  70403|\n",
      "|                FL|  69468|\n",
      "|                IN|  45525|\n",
      "|                MA|  38941|\n",
      "|                VA|  34367|\n",
      "|                MD|  30213|\n",
      "|                NC|  27152|\n",
      "|                TX|  18827|\n",
      "|                IL|  18666|\n",
      "|                GA|  17537|\n",
      "|                99|  16055|\n",
      "|                AZ|  12379|\n",
      "|                OH|  12281|\n",
      "|                CA|  12153|\n",
      "|                ME|  10806|\n",
      "|                SC|  10395|\n",
      "|                MN|  10083|\n",
      "|                OK|   9088|\n",
      "|                TN|   8514|\n",
      "|                DE|   7905|\n",
      "|                MI|   7231|\n",
      "|                RI|   5814|\n",
      "|                NH|   4119|\n",
      "|                VT|   3683|\n",
      "|                AL|   3178|\n",
      "|                WA|   3052|\n",
      "|                OR|   2622|\n",
      "|                MO|   2483|\n",
      "|                ON|   2460|\n",
      "|                WI|   2127|\n",
      "|                QB|   1998|\n",
      "|                IA|   1938|\n",
      "|                DC|   1929|\n",
      "|                CO|   1841|\n",
      "|                KY|   1795|\n",
      "|                DP|   1794|\n",
      "|                LA|   1689|\n",
      "|                MS|   1582|\n",
      "|                WV|   1265|\n",
      "|                AR|    994|\n",
      "|                SD|    859|\n",
      "|                NM|    792|\n",
      "|                ID|    763|\n",
      "|                NV|    725|\n",
      "|                KS|    706|\n",
      "|                NE|    704|\n",
      "|                UT|    561|\n",
      "|                MT|    505|\n",
      "|                GV|    348|\n",
      "|                NS|    322|\n",
      "|                AK|    298|\n",
      "|                ND|    254|\n",
      "|                WY|    188|\n",
      "|                HI|    156|\n",
      "|                AB|     79|\n",
      "|                PE|     61|\n",
      "|                NB|     57|\n",
      "|                BC|     54|\n",
      "|                PR|     38|\n",
      "|                MB|     17|\n",
      "|                SK|      9|\n",
      "|                FO|      8|\n",
      "+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the number of parking tickets per unique states from where the cars that got parking tickets came.\n",
    "from pyspark.sql.functions import count, countDistinct, desc, regexp_replace, sum, col\n",
    "\n",
    "unique_states = tickets.filter(year(\"Issue Date\")==2017).groupby(\"Registration State\")\\\n",
    "                .agg(countDistinct(\"Summons Number\"))\n",
    "unique_states = unique_states.withColumnRenamed(\"count(DISTINCT Summons Number)\",\"count\")\n",
    "unique_states.sort(desc(\"count\")).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|Registration State|  count|\n",
      "+------------------+-------+\n",
      "|                NY|4290006|\n",
      "+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# replacing 99 in Registration State with NY\n",
    "state_replace = unique_states.withColumn(\"Registration State\", regexp_replace(\"Registration State\", \"99\", \"NY\"))\n",
    "state_replace = state_replace.where(col(\"Registration State\") == \"NY\").groupby(\"Registration State\")\\\n",
    "                        .agg(sum(\"count\").alias(\"count\"))\n",
    "# total number of cars from NY\n",
    "state_replace.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|Registration State|  count|\n",
      "+------------------+-------+\n",
      "|                NY|4290006|\n",
      "|                NJ| 475825|\n",
      "|                PA| 140286|\n",
      "|                CT|  70403|\n",
      "|                FL|  69468|\n",
      "|                IN|  45525|\n",
      "|                MA|  38941|\n",
      "|                VA|  34367|\n",
      "|                MD|  30213|\n",
      "|                NC|  27152|\n",
      "|                TX|  18827|\n",
      "|                IL|  18666|\n",
      "|                GA|  17537|\n",
      "|                AZ|  12379|\n",
      "|                OH|  12281|\n",
      "|                CA|  12153|\n",
      "|                ME|  10806|\n",
      "|                SC|  10395|\n",
      "|                MN|  10083|\n",
      "|                OK|   9088|\n",
      "|                TN|   8514|\n",
      "|                DE|   7905|\n",
      "|                MI|   7231|\n",
      "|                RI|   5814|\n",
      "|                NH|   4119|\n",
      "|                VT|   3683|\n",
      "|                AL|   3178|\n",
      "|                WA|   3052|\n",
      "|                OR|   2622|\n",
      "|                MO|   2483|\n",
      "|                ON|   2460|\n",
      "|                WI|   2127|\n",
      "|                QB|   1998|\n",
      "|                IA|   1938|\n",
      "|                DC|   1929|\n",
      "|                CO|   1841|\n",
      "|                KY|   1795|\n",
      "|                DP|   1794|\n",
      "|                LA|   1689|\n",
      "|                MS|   1582|\n",
      "|                WV|   1265|\n",
      "|                AR|    994|\n",
      "|                SD|    859|\n",
      "|                NM|    792|\n",
      "|                ID|    763|\n",
      "|                NV|    725|\n",
      "|                KS|    706|\n",
      "|                NE|    704|\n",
      "|                UT|    561|\n",
      "|                MT|    505|\n",
      "|                GV|    348|\n",
      "|                NS|    322|\n",
      "|                AK|    298|\n",
      "|                ND|    254|\n",
      "|                WY|    188|\n",
      "|                HI|    156|\n",
      "|                AB|     79|\n",
      "|                PE|     61|\n",
      "|                NB|     57|\n",
      "|                BC|     54|\n",
      "|                PR|     38|\n",
      "|                MB|     17|\n",
      "|                SK|      9|\n",
      "|                FO|      8|\n",
      "+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = unique_states.select(\"Registration State\", \"count\")\\\n",
    "                    .where((col(\"Registration State\") != \"NY\") & (col(\"Registration State\") != \"99\"))\\\n",
    "                    .sort(desc(\"count\"))\n",
    "# combining dataframes with NY only count and remaining state counts to get the final dataframe\n",
    "unique_states_count = state_replace.union(temp)\n",
    "unique_states_count.sort(desc(\"count\")).show(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|unique_states_count|\n",
      "+-------------------+\n",
      "|                 64|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the number of unique states from where the cars that got parking tickets came.\n",
    "num_unique_states = unique_states_count.agg(countDistinct(\"Registration State\").alias(\"unique_states_count\"))\n",
    "num_unique_states.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1: Examine the data: RESULTS\n",
    "##### 1. Find the total number of tickets for the year.\n",
    "##### 5431918\n",
    "\n",
    "##### 2. Find out the number of unique states from where the cars that got parking tickets came.\n",
    "##### 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dataframe into a spark sql table/view\n",
    "tickets = tickets.withColumn(\"Registration State\", regexp_replace(\"Registration State\", \"99\", \"NY\"))\n",
    "\n",
    "tickets.cache()\n",
    "tickets.createOrReplaceTempView(\"v_tickets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|Violation Code|Frequency|\n",
      "+--------------+---------+\n",
      "|            21|   768087|\n",
      "|            36|   662765|\n",
      "|            38|   542079|\n",
      "|            14|   476664|\n",
      "|            20|   319646|\n",
      "+--------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. How often does each violation code occur? Display the frequency of the top five violation codes.\n",
    "violation_code_freq = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) AS Frequency FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 GROUP BY `Violation Code` ORDER BY Frequency desc LIMIT 5\"\"\") \n",
    "violation_code_freq.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+\n",
      "|Vehicle Body Type|Frequency|\n",
      "+-----------------+---------+\n",
      "|             SUBN|  1883954|\n",
      "|             4DSD|  1547312|\n",
      "|              VAN|   724029|\n",
      "|             DELV|   358984|\n",
      "|              SDN|   194197|\n",
      "+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2(a).How often does each 'vehicle body type' get a parking ticket?\n",
    "parking_tick_by_vehicle_body_type = spark.sql(\"\"\"SELECT `Vehicle Body Type`, count(`Summons Number`) AS Frequency FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 GROUP BY `Vehicle Body Type` ORDER BY Frequency desc LIMIT 5\"\"\")\n",
    "parking_tick_by_vehicle_body_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+\n",
      "|Vehicle Make|Frequency|\n",
      "+------------+---------+\n",
      "|        FORD|   636844|\n",
      "|       TOYOT|   605291|\n",
      "|       HONDA|   538884|\n",
      "|       NISSA|   462017|\n",
      "|       CHEVR|   356032|\n",
      "+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2(b).How often does each 'Vehicle Make' get a parking ticket?\n",
    "parking_tick_by_vehicle_Make = spark.sql(\"\"\"SELECT `Vehicle Make`, count(*) AS Frequency FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 GROUP BY `Vehicle Make` ORDER BY Frequency desc LIMIT 5\"\"\")\n",
    "parking_tick_by_vehicle_Make.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "|Violation Precinct|Frequency|\n",
      "+------------------+---------+\n",
      "|                 0|   925596|\n",
      "|                19|   274445|\n",
      "|                14|   203553|\n",
      "|                 1|   174702|\n",
      "|                18|   169131|\n",
      "|               114|   147444|\n",
      "+------------------+---------+\n",
      "\n",
      "+---------------+---------+\n",
      "|Issuer Precinct|Frequency|\n",
      "+---------------+---------+\n",
      "|              0|  1078406|\n",
      "|             19|   266961|\n",
      "|             14|   200495|\n",
      "|              1|   168740|\n",
      "|             18|   162994|\n",
      "|            114|   144054|\n",
      "+---------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3. Find the (5 highest) frequencies of tickets for each of the following:\n",
    "# Ignoring the entry with Violation & Issue Precinct as 0.\n",
    "#3(a): 'Violation Precinct'\n",
    "parking_tick_by_Violation_Precint = spark.sql(\"\"\"SELECT `Violation Precinct`, count(`Summons Number`) AS Frequency FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 GROUP BY `Violation Precinct` ORDER BY Frequency desc LIMIT 6\"\"\")\n",
    "parking_tick_by_Violation_Precint.show()\n",
    "\n",
    "#3(b): 'Issuer Precinct'\n",
    "parking_tick_by_Issuer_Precint = spark.sql(\"\"\"SELECT `Issuer Precinct`, count(`Summons Number`) AS Frequency FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 GROUP BY `Issuer Precinct` ORDER BY Frequency desc LIMIT 6\"\"\")\n",
    "parking_tick_by_Issuer_Precint.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precinct 19 tops as the highest number of parking tickets for a Violation Precinct. \n",
    "#### Precinct 19 also tops as the highest number of parking tickets for a Issuer Precinct.\n",
    "#### Address for Precint 19 is 153 E 67th St, New York, NY 10065, USA which means there is a higher number of parking violations happening around the 67th Street in NYC i.e. this area has severe problem of parking space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------------+\n",
      "|Violation Code|Freq of Violation Codes Prnct 19|\n",
      "+--------------+--------------------------------+\n",
      "|            46|                           48445|\n",
      "|            38|                           36386|\n",
      "|            37|                           36056|\n",
      "|            14|                           29797|\n",
      "|            21|                           28415|\n",
      "+--------------+--------------------------------+\n",
      "\n",
      "+--------------+--------------------------------+\n",
      "|Violation Code|Freq of Violation Codes Prnct 14|\n",
      "+--------------+--------------------------------+\n",
      "|            14|                           45036|\n",
      "|            69|                           30464|\n",
      "|            31|                           22555|\n",
      "|            47|                           18364|\n",
      "|            42|                           10027|\n",
      "+--------------+--------------------------------+\n",
      "\n",
      "+--------------+-------------------------------+\n",
      "|Violation Code|Freq of Violation Codes Prnct 1|\n",
      "+--------------+-------------------------------+\n",
      "|            14|                          38354|\n",
      "|            16|                          19081|\n",
      "|            20|                          15408|\n",
      "|            46|                          12745|\n",
      "|            38|                           8535|\n",
      "+--------------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4. Find the violation code frequencies for three precincts that have issued the most number of tickets\n",
    "# violation code frequncies for the top three precincts with highest frequency of tickets\n",
    "\n",
    "#From above question, we found out that precinct 19, 14 & 1 has issued the most number of parking tickets.\n",
    "#1. Finding the frequency of violation codes for precinct 19\n",
    "freq_prcnt_19_VCode = spark.sql(\"\"\"SELECT `Violation Code`,count(`Violation Code`) AS `Freq of Violation Codes Prnct 19` \n",
    "                                FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 AND `Issuer Precinct` = 19 \n",
    "                                GROUP BY `Violation Code` ORDER BY `Freq of Violation Codes Prnct 19` desc LIMIT 5\"\"\")\n",
    "\n",
    "freq_prcnt_19_VCode.show()\n",
    "\n",
    "#1. Finding the frequency of violation codes for precinct 19\n",
    "freq_prcnt_14_VCode = spark.sql(\"\"\"SELECT `Violation Code`,count(`Violation Code`) AS `Freq of Violation Codes Prnct 14` \n",
    "                                FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 AND `Issuer Precinct` = 14 \n",
    "                                GROUP BY `Violation Code` ORDER BY `Freq of Violation Codes Prnct 14` desc LIMIT 5\"\"\")\n",
    "\n",
    "freq_prcnt_14_VCode.show()\n",
    "\n",
    "#1. Finding the frequency of violation codes for precinct 19\n",
    "freq_prcnt_1_VCode = spark.sql(\"\"\"SELECT `Violation Code`,count(`Violation Code`) AS `Freq of Violation Codes Prnct 1` \n",
    "                                FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 AND `Issuer Precinct` = 1\n",
    "                                GROUP BY `Violation Code` ORDER BY `Freq of Violation Codes Prnct 1` desc LIMIT 5\"\"\")\n",
    "\n",
    "freq_prcnt_1_VCode.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count when column is null 0\n",
      "Count when column has 'nan' value 16\n",
      "+++++++++++AFTER CLEANING THE DATA++++++++++++++\n",
      "Count when column has 'nan': 0\n"
     ]
    }
   ],
   "source": [
    "#5(a) Find a way to deal with missing values\n",
    "from pyspark.sql.functions import isnan, isnull\n",
    "\n",
    "# Filtering Record for year 2017 only\n",
    "tickets_2017 = tickets.filter(year(\"Issue Date\")==2017)\n",
    "\n",
    "# Checking null or nan values in the Violation Time field\n",
    "null_count = tickets_2017.where(col(\"Violation Time\") == \"null\").count()\n",
    "print(\"Count when column is null\", null_count)\n",
    "\n",
    "nan_count = tickets_2017.where(col(\"Violation Time\") == \"nan\").count()\n",
    "print(\"Count when column has 'nan' value\", nan_count)\n",
    "\n",
    "#Since, the count of nan values is quite low, so we are safe to drop the rows with nan values \n",
    "#as it won't affect our results much.\n",
    "print(\"+++++++++++AFTER CLEANING THE DATA++++++++++++++\")\n",
    "tickets_2017_filtered = tickets_2017.filter(col(\"Violation Time\") != \"nan\")\n",
    "print(\"Count when column has 'nan':\", tickets_2017_filtered.filter(col(\"Violation Time\") == \"nan\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----+-------+---------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Hour|Minutes|TimeOfDay|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----+-------+---------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|         1120A|  11|     20|        A|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13 00:00:00|             7|             SUBN|       ME/BE|                 0|              0|         0852P|  08|     52|        P|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11 00:00:00|            78|             DELV|       FRUEH|               106|            106|         0015A|  00|     15|        A|\n",
      "|    1413656420|T672371C|                NY|2017-02-04 00:00:00|            40|             TAXI|       TOYOT|                73|             73|         0525A|  05|     25|        A|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26 00:00:00|            64|              VAN|       INTER|                17|             17|         0256P|  02|     56|        P|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5(b)The Violation Time field is specified in a strange format. \n",
    "#    Find a way to make this a time attribute that you can use to divide into groups.\n",
    "\n",
    "#converting the Violation Time column to timestamp\n",
    "from pyspark.sql.functions import substring\n",
    "\n",
    "tickets_2017_hour = tickets_2017_filtered.withColumn(\"Hour\",col(\"Violation Time\").substr(1,2))\n",
    "tickets_2017_min = tickets_2017_hour.withColumn(\"Minutes\", col(\"Violation Time\").substr(3,2))\n",
    "tickets_2017_new = tickets_2017_min.withColumn(\"TimeOfDay\",col(\"Violation Time\").substr(5,1))\n",
    "tickets_2017_new.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----+-------+---------+---------------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Hour|Minutes|TimeOfDay|Time of the Day|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----+-------+---------+---------------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|         1120A|  11|     20|        A|   LATE MORNING|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13 00:00:00|             7|             SUBN|       ME/BE|                 0|              0|         0852P|  08|     52|        P|   LATE MORNING|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11 00:00:00|            78|             DELV|       FRUEH|               106|            106|         0015A|  00|     15|        A|           DAWN|\n",
      "|    1413656420|T672371C|                NY|2017-02-04 00:00:00|            40|             TAXI|       TOYOT|                73|             73|         0525A|  05|     25|        A|        MORNING|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26 00:00:00|            64|              VAN|       INTER|                17|             17|         0256P|  02|     56|        P|           DAWN|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----+-------+---------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5(b)Divide 24 hours into six equal discrete bins of time. Choose the intervals as you see fit. \n",
    "#    For each of these groups, find the three most commonly occurring violations.\n",
    "\n",
    "# creating view after removing the null or nan values from Violation Field\n",
    "tickets_2017_new.createOrReplaceTempView(\"tickets_2017_new\")\n",
    "\n",
    "# Dividing Violation Time into 6 buckets\n",
    "violation_time_interval = spark.sql(\"\"\"SELECT *, CASE WHEN ((HOUR ==\"00\") OR (HOUR ==\"01\") OR (HOUR==\"02\") OR (HOUR==\"03\") AND (TimeOfDay == \"A\")) THEN \"DAWN\" WHEN ((HOUR ==\"04\") OR (HOUR ==\"05\") OR (HOUR==\"06\") OR (HOUR==\"07\") AND (TimeOfDay == \"A\")) THEN \"MORNING\" WHEN ((HOUR ==\"08\") OR (HOUR ==\"09\") OR (HOUR==\"10\") OR (HOUR==\"11\") AND (TimeOfDay == \"A\")) THEN \"LATE MORNING\" WHEN ((HOUR ==\"12\") OR (HOUR ==\"01\") OR (HOUR==\"02\") OR (HOUR==\"03\") AND (TimeOfDay == \"P\")) THEN \"AFTERNOON\" WHEN ((HOUR ==\"04\") OR (HOUR ==\"05\") OR (HOUR==\"06\") OR (HOUR==\"07\") AND (TimeOfDay == \"P\")) THEN \"DUSK\" WHEN ((HOUR ==\"08\") OR (HOUR ==\"09\") OR (HOUR==\"10\") OR (HOUR==\"11\") AND (TimeOfDay == \"P\")) THEN \"NIGHT\" END AS `Time of the Day` FROM tickets_2017_new\"\"\")\n",
    "\n",
    "violation_time_interval.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divided the Violation Time into 6 time intervals:\n",
    "#### 1. DAWN - 00 HRS to 03 Hrs (AM)\n",
    "#### 2. MORNING - 04 HRS to 07 Hrs (AM)\n",
    "#### 3. LATE MORNING - 08 HRS to 11 Hrs (AM)\n",
    "#### 4. AFTERNOON - 12 HRS to 03 Hrs (PM)\n",
    "#### 5. DUSK - 04 HRS to 07 Hrs (PM)\n",
    "#### 6. NIGHT - 08 HRS to 11 Hrs (PM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+\n",
      "|Violation Code|count_VCode_dawn|\n",
      "+--------------+----------------+\n",
      "|            85|            6654|\n",
      "|            76|               6|\n",
      "|            91|              75|\n",
      "+--------------+----------------+\n",
      "\n",
      "+--------------+-------------------+\n",
      "|Violation Code|count_VCode_morning|\n",
      "+--------------+-------------------+\n",
      "|            85|                670|\n",
      "|            76|                  5|\n",
      "|            22|                 20|\n",
      "+--------------+-------------------+\n",
      "\n",
      "+--------------+--------------------+\n",
      "|Violation Code|count_VCode_late_mor|\n",
      "+--------------+--------------------+\n",
      "|            53|                6840|\n",
      "|            78|                7375|\n",
      "|            27|                1276|\n",
      "+--------------+--------------------+\n",
      "\n",
      "+--------------+-----------------+\n",
      "|Violation Code|count_VCode_aftrn|\n",
      "+--------------+-----------------+\n",
      "|            31|            16583|\n",
      "|            78|             1670|\n",
      "|            27|              440|\n",
      "+--------------+-----------------+\n",
      "\n",
      "+--------------+----------------+\n",
      "|Violation Code|count_VCode_dusk|\n",
      "+--------------+----------------+\n",
      "|            31|              24|\n",
      "|            76|               2|\n",
      "|            47|               5|\n",
      "+--------------+----------------+\n",
      "\n",
      "+--------------+-----------------+\n",
      "|Violation Code|count_VCode_night|\n",
      "+--------------+-----------------+\n",
      "|            85|              230|\n",
      "|            27|                7|\n",
      "|            13|               63|\n",
      "+--------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#three most occuring violations for each time interval\n",
    "violation_time_interval.createOrReplaceTempView(\"violation_per_time_interval\")\n",
    "# 3 most violation for dawn\n",
    "three_most_violation_dawn = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) As count_VCode_dawn FROM violation_per_time_interval WHERE `Time of the Day`== \"DAWN\" GROUP BY `Violation Code` LIMIT 3\"\"\")\n",
    "three_most_violation_dawn.show()\n",
    "\n",
    "# 3 most violation for morning\n",
    "three_most_violation_morning = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) As count_VCode_morning FROM violation_per_time_interval WHERE `Time of the Day`== \"MORNING\" GROUP BY `Violation Code` LIMIT 3\"\"\")\n",
    "three_most_violation_morning.show()\n",
    "\n",
    "# 3 most violation for late morning\n",
    "three_most_violation_late_morning = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) As count_VCode_late_mor FROM violation_per_time_interval WHERE `Time of the Day`== \"LATE MORNING\" GROUP BY `Violation Code` LIMIT 3\"\"\")\n",
    "three_most_violation_late_morning.show()\n",
    "\n",
    "# 3 most violation for afternoon\n",
    "three_most_violation_afternoon = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) As count_VCode_aftrn FROM violation_per_time_interval WHERE `Time of the Day`== \"AFTERNOON\" GROUP BY `Violation Code` LIMIT 3\"\"\")\n",
    "three_most_violation_afternoon.show()\n",
    "\n",
    "# 3 most violation for dusk\n",
    "three_most_violation_dusk= spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) As count_VCode_dusk FROM violation_per_time_interval WHERE `Time of the Day`== \"DUSK\" GROUP BY `Violation Code` LIMIT 3\"\"\")\n",
    "three_most_violation_dusk.show()\n",
    "\n",
    "# 3 most violation for night\n",
    "three_most_violation_night = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) As count_VCode_night FROM violation_per_time_interval WHERE `Time of the Day`== \"NIGHT\" GROUP BY `Violation Code` LIMIT 3\"\"\")\n",
    "three_most_violation_night.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+\n",
      "|Violation Code|Three_most_common_VCode|\n",
      "+--------------+-----------------------+\n",
      "|            53|                  19488|\n",
      "|            81|                     14|\n",
      "|            44|                      4|\n",
      "+--------------+-----------------------+\n",
      "\n",
      "+---------------+--------------+\n",
      "|Time Of the Day|Violation Code|\n",
      "+---------------+--------------+\n",
      "|           DAWN|          5243|\n",
      "|      AFTERNOON|          3274|\n",
      "|   LATE MORNING|          8207|\n",
      "|           DUSK|           180|\n",
      "|        MORNING|          6125|\n",
      "|          NIGHT|           158|\n",
      "+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For the three most commonly occurring violation codes, find the most common time of the day\n",
    "common_time_for_violation = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) as Three_most_common_VCode FROM violation_per_time_interval GROUP BY `Violation Code` LIMIT 3\"\"\")\n",
    "common_time_for_violation.show()\n",
    "\n",
    "common_time_for_violation= spark.sql(\"\"\"SELECT `Time Of the Day`, count(`Summons Number`) `Violation Code` FROM violation_per_time_interval WHERE `Violation Code` in (53,27,26) GROUP BY `Time Of the Day`\"\"\")\n",
    "common_time_for_violation.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.Let’s try and find some seasonality in this data:\n",
    "First, divide the year into a certain number of seasons, and find the frequencies of tickets for each season. (Hint: Use Issue Date to segregate into seasons.)\n",
    "Then, find the three most common violations for each of these seasons..**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this first we convert string issue date into date \n",
    "* then we extract month from it \n",
    "* according to month we will assign season.\n",
    "* count number of tickits for each season\n",
    "* then we count top 3 code for each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Issue Date|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|         1120A|2017-06-14|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13 00:00:00|             7|             SUBN|       ME/BE|                 0|              0|         0852P|2017-06-13|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11 00:00:00|            78|             DELV|       FRUEH|               106|            106|         0015A|2017-01-11|\n",
      "|    1413656420|T672371C|                NY|2017-02-04 00:00:00|            40|             TAXI|       TOYOT|                73|             73|         0525A|2017-02-04|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26 00:00:00|            64|              VAN|       INTER|                17|             17|         0256P|2017-01-26|\n",
      "|    1416638830|  GLP367|                NY|2017-04-30 00:00:00|            20|             SUBN|       DODGE|                17|             17|         1232A|2017-04-30|\n",
      "|    4630524241|  HJBP29|                FL|2017-02-03 00:00:00|            36|               4D|         BMW|                 0|              0|         1034A|2017-02-03|\n",
      "|    8505131836| 87155MA|                NY|2017-05-27 00:00:00|            38|              VAN|       CHEVR|                 1|              1|         1021A|2017-05-27|\n",
      "|    8513520615| 77026MG|                NY|2017-05-31 00:00:00|            14|             TRAC|       VOLVO|                24|             24|         0721A|2017-05-31|\n",
      "|    8556155431| HFB9919|                NY|2017-05-26 00:00:00|            75|             4DSD|       DODGE|               114|            114|         0940A|2017-05-26|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tickets_2017.createOrReplaceTempView(\"Q6\")\n",
    "df_Q6=spark.sql('select *,cast(`Issue Date` AS date) from Q6')\n",
    "df_Q6.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+-----+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Month|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+-----+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|         1120A|    6|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13 00:00:00|             7|             SUBN|       ME/BE|                 0|              0|         0852P|    6|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11 00:00:00|            78|             DELV|       FRUEH|               106|            106|         0015A|    1|\n",
      "|    1413656420|T672371C|                NY|2017-02-04 00:00:00|            40|             TAXI|       TOYOT|                73|             73|         0525A|    2|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26 00:00:00|            64|              VAN|       INTER|                17|             17|         0256P|    1|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tickets_2017.createOrReplaceTempView(\"Q61\")\n",
    "\n",
    "df_Q61=spark.sql('select *,month(`Issue Date`)as Month from Q61')\n",
    "df_Q61.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+-----+------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Month|Season|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+-----+------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|         1120A|    6|Summer|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13 00:00:00|             7|             SUBN|       ME/BE|                 0|              0|         0852P|    6|Summer|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11 00:00:00|            78|             DELV|       FRUEH|               106|            106|         0015A|    1|Winter|\n",
      "|    1413656420|T672371C|                NY|2017-02-04 00:00:00|            40|             TAXI|       TOYOT|                73|             73|         0525A|    2|Summer|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26 00:00:00|            64|              VAN|       INTER|                17|             17|         0256P|    1|Winter|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+---------------------+\n",
      "| Season|count(Summons Number)|\n",
      "+-------+---------------------+\n",
      "| Summer|              4552537|\n",
      "| Winter|               878061|\n",
      "|Monsson|                 1320|\n",
      "+-------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Q61.createOrReplaceTempView(\"Q62\")\n",
    "df_Q62=spark.sql('select *,Case When Month in(7,8,9,10) then \"Monsson\" When Month in(2,3,4,5,6) then \"Summer\" Else\"Winter\" End as Season from Q62')\n",
    "df_Q62.show(5)\n",
    "df_Q62.groupby('Season').agg({'Summons Number' : 'count'}).sort(col('count(Summons Number)').desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Summer has higest frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Q62.createOrReplaceTempView(\"Q63\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Winter **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+\n",
      "|Violation code|count(Violation code)|\n",
      "+--------------+---------------------+\n",
      "|            36|               129769|\n",
      "|            21|               119931|\n",
      "|            38|                95451|\n",
      "+--------------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Q6_winter=spark.sql('select `Violation code` from Q63 where `Season`=\"Winter\"')\n",
    "df_Q6_winter.groupby('Violation code').agg({'Violation code' : 'count'}).sort(col('count(Violation code)').desc()).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Summer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+\n",
      "|Violation code|count(Violation code)|\n",
      "+--------------+---------------------+\n",
      "|            21|               647909|\n",
      "|            36|               532996|\n",
      "|            38|               446618|\n",
      "+--------------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Q6_Summer=spark.sql('select `Violation code` from Q63 where `Season`=\"Summer\"')\n",
    "df_Q6_Summer.groupby('Violation code').agg({'Violation code' : 'count'}).sort(col('count(Violation code)').desc()).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Monsson **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+\n",
      "|Violation code|count(Violation code)|\n",
      "+--------------+---------------------+\n",
      "|            46|                  287|\n",
      "|            21|                  247|\n",
      "|            40|                  146|\n",
      "+--------------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Q6_Monsson=spark.sql('select `Violation code` from Q63 where `Season`=\"Monsson\"')\n",
    "df_Q6_Monsson.groupby('Violation code').agg({'Violation code' : 'count'}).sort(col('count(Violation code)').desc()).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For each season we get same code in top3 which are 21,36,38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.The fines collected from all the instances of parking violation constitute a source of revenue for the NYC Police Department. Let’s take an example of estimating this for the three most commonly occurring codes:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We count number of ticket fo each code then we multiply top 3 code with find which we get from previous question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQ7=tickets_2017.cube('Violation code').count().sort(col('count').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+\n",
      "|Violation code|  count|\n",
      "+--------------+-------+\n",
      "|          null|5431918|\n",
      "|            21| 768087|\n",
      "+--------------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfQ7.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For 21 code total  768087 tickets are issued\n",
    " for 36 1400614 tickets and for 38 1062304 tickets are issued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
